<img src="AKHRAIS HASNAE.jpg" style="height:464px;margin-right:432px"/>
        # ğŸ“Š Rapport de Projet : Analyse et ModÃ©lisation sur le Dataset UCI Mushroom
# ğŸ“Š Rapport de Projet â€” ModÃ©lisation & Analyse de DonnÃ©es

## Projet 3 â€” Hasnae Akhrais

---

## 1. Introduction

### ğŸ¯ Contexte

Ce projet sâ€™inscrit dans le cadre dâ€™un travail de modÃ©lisation prÃ©dictive visant Ã  analyser un jeu de donnÃ©es dont lâ€™objectif principal est de construire un modÃ¨le performant capable de prÃ©dire une variable cible Ã  partir de donnÃ©es numÃ©riques et catÃ©gorielles.

Lâ€™analyse est orientÃ©e machine learning et comprend exploration, nettoyage, traitement, entraÃ®nement et Ã©valuation de plusieurs modÃ¨les.

### â“ ProblÃ©matique

Comment transformer un dataset brut, contenant des valeurs manquantes, des variables de types diffÃ©rents et potentiellement du bruit, en un modÃ¨le prÃ©dictif fiable et gÃ©nÃ©ralisable ?

### ğŸ¯ Objectifs

* Comprendre la structure du dataset via une **analyse exploratoire (EDA)**.
* Appliquer un **prÃ©traitement rigoureux** : imputation, encodage, standardisation.
* Comparer diffÃ©rents **algorithmes de machine learning**.
* Ã‰valuer les performances via des **mÃ©triques adaptÃ©es** (Accuracy, F1-score, ROC-AUC, RMSE).
* Identifier les **erreurs** du modÃ¨le et discuter de ses limites.

---

## 2. MÃ©thodologie

### ğŸ§¼ 2.1 Nettoyage & PrÃ©traitement

âœ” **Imputation KNN**
Le choix du `KNNImputer` pour les variables numÃ©riques se justifie par sa capacitÃ© Ã  reconstruire les valeurs manquantes en se basant sur la similaritÃ© des observations. Contrairement Ã  une moyenne ou mÃ©diane, KNN prÃ©serve mieux la structure multivariÃ©e.

âœ” **Encodage des variables catÃ©gorielles**
Les modÃ¨les nÃ©cessitant des entrÃ©es numÃ©riques, un encodage (One-Hot Encoding ou Ã©quivalent) a Ã©tÃ© appliquÃ©.
Ce choix garantit que les relations non ordinales entre catÃ©gories ne sont pas mal interprÃ©tÃ©es.

âœ” **Standardisation**
La normalisation des variables numÃ©riques a Ã©tÃ© appliquÃ©e afin dâ€™amÃ©liorer les performances de modÃ¨les sensibles Ã  lâ€™Ã©chelle (KNN, SVM, rÃ©gression logistiqueâ€¦).

---

### ğŸ¤– 2.2 Choix des Algorithmes

Plusieurs modÃ¨les ont Ã©tÃ© testÃ©s pour comparer diffÃ©rents comportements :

* **RÃ©gression Logistique** â†’ baseline robuste, interprÃ©table, adaptÃ©e aux problÃ¨mes linÃ©aires.
* **Random Forest / XGBoost** â†’ modÃ¨les plus puissants, capables de gÃ©rer des relations non linÃ©aires.
* **KNN** â†’ benchmark simple basÃ© sur la proximitÃ©.
* **SVM** â†’ performant sur les datasets propres et bien standardisÃ©s.

Le choix final du modÃ¨le se base sur la validation croisÃ©e, lâ€™analyse des mÃ©triques et la capacitÃ© du modÃ¨le Ã  gÃ©nÃ©raliser.

---

### ğŸ§ª 2.3 Validation & Optimisation

* Utilisation de **KFold** pour rÃ©duire la variance de lâ€™Ã©valuation.
* Recherche dâ€™hyperparamÃ¨tres via **GridSearchCV**.
* SÃ©paration standard en **train/test** pour mesurer la performance finale.

---

## 3. RÃ©sultats & Discussion

### ğŸ“ˆ 3.1 MÃ©triques de performance

Selon les rÃ©sultats obtenus dans le notebook, les mÃ©triques principales incluent :

* **Accuracy** : mesure globale de bonnes prÃ©dictions.
* **F1-Score** : pertinent en cas de classes dÃ©sÃ©quilibrÃ©es.
* **ROC-AUC** : Ã©value la capacitÃ© discriminative du modÃ¨le.
* **RMSE** (si applicable Ã  un modÃ¨le de rÃ©gression).

Les modÃ¨les dâ€™ensemble (Random Forest, XGBoost) tendent gÃ©nÃ©ralement Ã  obtenir les meilleurs scores grÃ¢ce Ã  leur robustesse et leur capacitÃ© Ã  capturer des relations complexes.

---

### ğŸ§© 3.2 Analyse des erreurs

Lâ€™analyse de la **matrice de confusion** met en Ã©vidence :

* Les types dâ€™erreurs les plus frÃ©quents (faux positifs / faux nÃ©gatifs).
* Les classes que le modÃ¨le a du mal Ã  distinguer.

Cela permet dâ€™identifier :

* Les caractÃ©ristiques mal apprises.
* La nÃ©cessitÃ© potentielle dâ€™un rÃ©Ã©quilibrage (SMOTE, pÃ©nalisationâ€¦).
* Des pistes dâ€™amÃ©lioration de la qualitÃ© des donnÃ©es.

---

## 4. Conclusion

### âœ”ï¸ Limites du ModÃ¨le

* SensibilitÃ© possible aux valeurs aberrantes malgrÃ© lâ€™imputation.
* Performances dÃ©pendantes de la qualitÃ© du preprocessing.
* DifficultÃ© Ã  gÃ©nÃ©raliser si les donnÃ©es sont dÃ©sÃ©quilibrÃ©es ou insuffisantes.
* Risque de surapprentissage avec certains modÃ¨les complexes (Random Forest, XGBoost).

### ğŸš€ Pistes dâ€™AmÃ©lioration

* Tester dâ€™autres techniques dâ€™Ã©quilibrage de classes.
* Ajouter une sÃ©lection ou extraction de features (PCA, tests statistiques).
* Collecter davantage de donnÃ©es ou enrichir les variables.
* Tester des modÃ¨les plus rÃ©cents (LightGBM, CatBoost).
* Optimiser plus finement les hyperparamÃ¨tres.

---

## ğŸ–‹ï¸ Auteur

Projet rÃ©alisÃ© par **Hasnae Akhrais** dans le cadre du Projet 3.


